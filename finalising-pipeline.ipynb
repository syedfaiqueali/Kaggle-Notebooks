{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7962198,"sourceType":"datasetVersion","datasetId":4619135}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai==1.14.2","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-28T08:43:43.327858Z","iopub.execute_input":"2024-03-28T08:43:43.328232Z","iopub.status.idle":"2024-03-28T08:44:00.525814Z","shell.execute_reply.started":"2024-03-28T08:43:43.328204Z","shell.execute_reply":"2024-03-28T08:44:00.524634Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai==1.14.2\n  Downloading openai-1.14.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (2.5.3)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai==1.14.2) (4.9.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.14.2) (3.6)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.14.2) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.14.2) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.14.2) (1.0.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.14.2) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.14.2) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.14.2) (2.14.6)\nDownloading openai-1.14.2-py3-none-any.whl (262 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: openai\nSuccessfully installed openai-1.14.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import io\nimport re\nimport os\nimport json\nimport base64\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfrom openai import OpenAI","metadata":{"execution":{"iopub.status.busy":"2024-03-28T08:44:00.527636Z","iopub.execute_input":"2024-03-28T08:44:00.528043Z","iopub.status.idle":"2024-03-28T08:44:03.158818Z","shell.execute_reply.started":"2024-03-28T08:44:00.528010Z","shell.execute_reply":"2024-03-28T08:44:03.157589Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Constant","metadata":{}},{"cell_type":"code","source":"# Env variables\nos.environ[\"OPEN_API_KEY\"] = \"API-KEY\"\n\n# File Paths\nCLEANED_DATA_PATH = '/kaggle/input/rta-dubai/sample_clean_application_data_2.xlsx'\nUNCLEANED_DATA_PATH = '/kaggle/input/rta-dubai/sample_unclean_application_data_v2.xlsx'\nMETADATA_PATH = '/kaggle/input/rta-dubai/Application dataset.json'\n\nOPEN_AI_CLIENT = OpenAI(api_key=os.getenv(\"OPEN_API_KEY\") ,organization='org-2EugvoZZidKLd5DkFH3dGTIA')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T08:44:03.160564Z","iopub.execute_input":"2024-03-28T08:44:03.161047Z","iopub.status.idle":"2024-03-28T08:44:03.184309Z","shell.execute_reply.started":"2024-03-28T08:44:03.161017Z","shell.execute_reply":"2024-03-28T08:44:03.182863Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"class MetaData:\n    def __init__(self, data):\n        self.__dict__ = data","metadata":{"execution":{"iopub.status.busy":"2024-03-28T04:31:59.078732Z","iopub.execute_input":"2024-03-28T04:31:59.079045Z","iopub.status.idle":"2024-03-28T04:31:59.084121Z","shell.execute_reply.started":"2024-03-28T04:31:59.079018Z","shell.execute_reply":"2024-03-28T04:31:59.082684Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Helper Function","metadata":{}},{"cell_type":"code","source":"def load_json_and_map_to_class(json_path):\n    try:\n        with open(json_path, 'r') as json_file:\n            data = json.load(json_file)\n            return MetaData(data)\n    except json.JSONDecodeError:\n        print(f\"Error: Unable to decode JSON from file '{file_path}'. File may be empty or not in valid JSON format.\")\n        return None\n\n\ndef extract_column_attributes_for_column_name_mapping(metadata_json):\n    columns_meta_data = []\n    for column in metadata_json.attributes:\n        columns_meta_data.append({\n            \"attribute_name\": column['attribute_name'],\n            \"description\": column['description'],\n            \"description\": column['description']\n        })\n    return json.dumps(columns_meta_data)\n\n\ndef convert_dataframe_to_html(dataframe):\n    html_string = dataframe.to_html()\n    return html_string.replace('\\n', '')\n\n\ndef extract_python_code(sample_string):\n    # Define a regular expression pattern to match Python code blocks\n    pattern = r'```python\\n(.*?)```'\n\n    # Find all matches of the pattern in the sample string\n    matches = re.findall(pattern, sample_string, re.DOTALL)\n\n    # Return the Python code blocks found\n    return matches\n\n\ndef convert_column_types_and_map_values_wrt_metadata(metadata_json, dataframe):\n    for column in metadata_json.attributes:\n        if column['attribute_name'] in dataframe.columns:\n            if column['data_type'].lower() == \"string\":\n                dataframe[column[\"attribute_name\"]] = dataframe[column[\"attribute_name\"]].astype(str)\n            elif column['data_type'].lower() == \"enum\":\n                # Check if enum value transformation required\n                if column['is_transformation_required']:\n                    dataframe[column[\"attribute_name\"]] = dataframe[column[\"attribute_name\"]].astype(str).str.lower().map(column['values'])\n                dataframe[column[\"attribute_name\"]] = dataframe[column[\"attribute_name\"]].astype('category')\n            elif column['data_type'].lower() == \"date\":\n                dataframe[column[\"attribute_name\"]] = dataframe[column[\"attribute_name\"]].astype('datetime64[ns]')\n                \n    return dataframe\n\n\ndef check_if_any_new_column_formation_is_required(dataframe, metadata_json):\n    new_columns_data = []\n    for column in metadata_json.attributes:\n        if (column['attribute_name'] not in dataframe) and column['constraints']:\n            column_name = column['attribute_name']\n            column_type = column['data_type']\n            column_desc = column['constraints'][0]\n            new_columns_data.append((column_name, column_type, column_desc))\n    return new_columns_data\n\n\ndef extract_df_column_names(dataframe):\n    return \", \".join(dataframe.columns.tolist())\n\n\ndef extract_df_column_names_with_datatypes(dataframe):\n    columns_data_types = {col: str(dtype) for col, dtype in dataframe.dtypes.items()}\n    json_data = json.dumps(columns_data_types)\n    return json_data\n\n\ndef execute_python_script(python_script):\n    slice_script = python_script[9:-3]\n    exec(slice_script)\n    \n\ndef read_saved_dataframe_output():\n    with open('output.txt', 'r') as file:\n        html_content = file.read()\n\n    return html_content\n\n\ndef read_saved_plot_output():\n    with open('output.png', 'rb') as img_file:\n        img_base64 = base64.b64encode(img_file.read()).decode('utf-8')\n    return img_base64\n\n\ndef read_saved_dataframe_new_col_output():\n    with open('dataframe.txt', 'r') as file:\n        html_content = file.read()\n\n    # Parse HTML content and convert to DataFrame\n    # [TODO] Later remove this, as only for notebook perspective\n    return pd.read_html(html_content)[0]\n\n\ndef contains_visual_keywords(text):\n    visual_keywords = ['plot', 'graph', 'chart', 'visualization']\n    pattern = re.compile(r'\\b(?:' + '|'.join(visual_keywords) + r')\\b', flags=re.IGNORECASE)\n    return True if re.search(pattern, text) else False\n\n\ndef get_html_tag_for_base64_image(img_base64):\n    return f'<img src=\"data:image/png;base64,{img_base64}\" style=\"max-width: 100%; max-height: 100%;\" alt=\"output\">'\n\n\ndef get_dataframe_dtypes_metadata(dataframe):\n    column_types = {col: str(dataframe[col].dtype) for col in dataframe.columns}\n    return json.dumps(column_types)\n\n\ndef load_finalised_csv_dtypes_metadata():\n    with open('finalised_metadata.json', 'r') as json_file:\n        return json.load(json_file)\n\n    \ndef show_saved_output_img():\n    img = mpimg.imread('output.png')\n    img_height, img_width, _ = img.shape\n    aspect_ratio = img_width / img_height\n    fig_width = 10  # Set a default width\n    fig_height = fig_width / aspect_ratio\n    fig = plt.figure(figsize=(fig_width, fig_height))\n    plt.imshow(img, interpolation='nearest')\n    plt.axis('off')\n    plt.tight_layout()\n    # return fig  # Return the figure object","metadata":{"execution":{"iopub.status.busy":"2024-03-28T04:57:55.475329Z","iopub.execute_input":"2024-03-28T04:57:55.475969Z","iopub.status.idle":"2024-03-28T04:57:55.496500Z","shell.execute_reply.started":"2024-03-28T04:57:55.475936Z","shell.execute_reply":"2024-03-28T04:57:55.495680Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# OpenAI Utils","metadata":{}},{"cell_type":"code","source":"class RTA_Bot:\n    _instance = None\n\n    def __new__(cls, *args, **kwargs):\n        if not cls._instance:\n            cls._instance = super().__new__(cls, *args, **kwargs)\n        return cls._instance\n\n    @staticmethod\n    def ask(prompt):\n        return OPEN_AI_CLIENT.chat.completions.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[\n            {\n                \"role\": \"user\",\n                \"content\": prompt,\n            }],\n        ).choices[0].message.content","metadata":{"execution":{"iopub.status.busy":"2024-03-28T04:57:56.430891Z","iopub.execute_input":"2024-03-28T04:57:56.431297Z","iopub.status.idle":"2024-03-28T04:57:56.437354Z","shell.execute_reply.started":"2024-03-28T04:57:56.431261Z","shell.execute_reply":"2024-03-28T04:57:56.436312Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def map_column_names_wrt_meta_data(dataset_column_names, metadata_json):\n    prompt = f\"\"\"\nRole: Act as a data analyst whose job is to help in transforming the dataset.\nTask: Consider below defined \"dataset_column_names\". Look up the \"columns_meta_data_json\" and pick relevant column attribute_name w.r.t to the attribute description and synonyms context only where required. Output should be a json with key as 'dataset_column_names' and value as attribute_name picked from columns_meta_data_json\n\ndataset_column_names: {dataset_column_names}\n\ncolumns_meta_data_json: \n{metadata_json}\n\nOutput: Return output in JSON Format defined under sample output.\n\nSample Output: {{\"Column1 Old Name\": \"Column1 New Name\", \"Column2 Old Name\": \"Column2 New Name\", ...}}\n\"\"\"\n    response = RTA_Bot.ask(prompt)\n    response = json.loads(response)\n    response = {key: value for key, value in response.items() if value != \"\" and value is not None}\n    return response\n\n\ndef ask_rta_bot(question):\n    column_names = load_finalised_csv_dtypes_metadata()\n    \n    if contains_visual_keywords(question):\n        execute_visual_prompt(question,column_names)\n    else:\n        output_dataframe = execute_dataframe_prompt(question, column_names)\n        return output_dataframe\n\n\ndef execute_dataframe_prompt(question, column_names):\n    prompt = f\"\"\" \nRole: Act as a data analyst whose job is to extract insights from the dataset based on the users asked questions.\n\nTask: Write a valid Python script for the below-mentioned \"user_question\". Load \"finalised.csv\" only for querying the data.\n\nuser_question: {question}\n\n\"finalised.csv\" pandas columns names and their types: {column_names}\n\noutput: The output should only be a valid python script\n\nScript steps:\n1. Read .csv file named 'finalised.csv'\n2. Convert the data types of the above read 'finalised.csv' dataframe as per the datatypes defined above\n3. Code for the task\n4. Form a pandas dataframe of the final output\n5. Then convert output dataframe into html string\n6. Save the output into a file named 'output.txt'\n\"\"\"\n    print(prompt)\n    try:\n        # Generate response\n        python_script = RTA_Bot.ask(prompt)\n        print(python_script)\n\n        # Execute script\n        execute_python_script(python_script)\n\n        # Read output dataframe as html table tag\n        output = read_saved_dataframe_output()\n\n        # Remove file\n        # os.remove('output.txt')\n\n        # Return output\n        return output\n    except Exception as e:\n        print(\"I apologize, but I'm currently unable to fulfill your request. Could you please try again or provide me more details to assist me in better understanding your request?\")\n        print(e)\n        return None\n    \n    \ndef execute_visual_prompt(question, column_names):\n    prompt = f\"\"\" \nRole: Act as a data analyst whose job is extract insights from the dataset based on the users asked question.\n\nTask: Write a valid python script for the below mentioned \"user_question\". Load \"finalised.csv\" only for querying the data.\n\nuser_question: {question}\n\n\"finalised.csv\"  pandas columns names and their types: {column_names}\n\noutput: The output should only be a valid python script\n\nScript steps:\n1. Read .csv file named 'finalised.csv'\n2. Convert the data types of the above read 'finalised.csv' dataframe as per the datatypes defined above\n3. Code for the user's asked question.\n4. Form a plot as the final output, no need to write plt.show() code.\n5. Save the output plot as a .png file named 'output.png'\n\"\"\"\n    print(prompt)\n    try:\n        # Generate response\n        python_script = RTA_Bot.ask(prompt)\n        print(python_script)\n\n        # Execute script\n        execute_python_script(python_script)\n\n        # Read output image as html image tag\n        output = get_html_tag_for_base64_image(read_saved_plot_output())\n        \n        # [REMOVE]\n        # show_saved_output_img()\n        \n        # Remove file\n        # os.remove('output.png')\n\n        # Return output\n        return output\n        \n    except Exception as e:\n        print(\"I apologize, but I'm currently unable to fulfill your request. Could you please try again or provide me more details to assist me in better understanding your request?\")\n        print(e)\n        return None\n\ndef execute_create_new_column_prompt(new_column, existing_df_columns_metadata):\n    new_column_name = new_column[0]\n    new_column_type = new_column[1]\n    new_column_desc = new_column[2]\n    \n    prompt = f\"\"\"\nRole: Act as a data analyst whose job is to create new columns from the below defined 'finalised.csv' data columns names and their data types.\n\nTask: Write a valid python script for the below mentioned \"user_question\". Use 'finalised.csv' only for querying the data.\n\nuser_question: Create a new column named \"{new_column_name}\" with type {new_column_type} and constraints as {new_column_desc}.\n\nexisting pandas columns names and their types: {existing_df_columns_metadata}\n\nScript steps:\n1. Read .csv file named 'finalised.csv'\n2. Convert the data types of the above read 'finalised.csv' dataframe as per the datatypes defined above\n3. Code for the task.\n4. Form a pandas dataframe of the final output with newly added column and its supporting column.\n5. Then convert output dataframe into html string\n6. Save the output into a file named 'dataframe.txt'\n\n    \"\"\"\n    try:\n        # Generate response\n        python_script = RTA_Bot.ask(prompt)\n        print(python_script)\n        \n        # Execute script\n        execute_python_script(python_script)\n\n        # Read output dataframe as html table tag\n        output = read_saved_dataframe_new_col_output()\n\n        # Remove file\n        # os.remove('dataframe.txt')\n\n        # Return output\n        return output\n    except Exception as e:\n        print(\"--------Error in new column formation--------\")\n        print(prompt)\n        print(e)\n        return None\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T05:13:39.201792Z","iopub.execute_input":"2024-03-28T05:13:39.202179Z","iopub.status.idle":"2024-03-28T05:13:39.217313Z","shell.execute_reply.started":"2024-03-28T05:13:39.202152Z","shell.execute_reply":"2024-03-28T05:13:39.216211Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline\n\n1. Extract **unclean dataset column names** and **attributes objects** from the meta-data.\n2. Use Open-AI to map **column new names** w.r.t to the provided meta-data.\n3. Change columns names.\n4. Transform columns types and their values w.r.t to the **metadata**\n5. Check if new columns formation is left w.r.t to the **metadata**\n6. Talk with the transformed dataset\n\n\n# Code","metadata":{}},{"cell_type":"code","source":"def execute_pipline():\n    # -------------------------------------------------------\n    # 1. Read the un-cleaned dataset and metadata json\n    # -------------------------------------------------------\n    df_uncleaned = pd.read_excel(UNCLEANED_DATA_PATH)\n    metadata_json = load_json_and_map_to_class(METADATA_PATH)\n    \n    \n    # -------------------------------------------------------\n    # 2. Column name mapping w.r.t metadata json\n    # -------------------------------------------------------\n    # Extract old dataset column names as list of string\n    old_column_names = df_uncleaned.columns.tolist()\n\n    # Find column names w.r.t metadata whose names are already correct\n    metadata_attributes = {attr['attribute_name'] for attr in metadata_json.attributes}\n    remove_column_names = [col_name for col_name in old_column_names if col_name in metadata_attributes]\n    \n    # Filter column and their metadata whose names are not correct\n    remaining_col_names = [col_name for col_name in old_column_names if col_name not in remove_column_names]\n    remaining_col_meta_data = []\n    for attr in metadata_json.attributes:\n        if attr['attribute_name'] not in remove_column_names:\n            remaining_col_meta_data.append({\n                \"attribute_name\": attr['attribute_name'],\n                \"description\": attr['description'],\n                \"synonyms\": attr['synonyms']\n            })\n    \n    remaining_col_metadata = json.dumps(remaining_col_meta_data)\n\n    # Use Open-Ai to map new column names w.r.t to context\n    uncleaned_column_new_names = map_column_names_wrt_meta_data(remaining_col_names, remaining_col_metadata)\n\n    # Rename columns\n    df_uncleaned.rename(columns=uncleaned_column_new_names, inplace=True)\n    \n    # -------------------------------------------------------\n    # 3. Convert column type w.r.t metadata json\n    # -------------------------------------------------------\n    df_uncleaned = convert_column_types_and_map_values_wrt_metadata(metadata_json, df_uncleaned)\n    df_uncleaned.to_csv('finalised.csv', index=False)\n    with open('finalised_metadata.json', \"w\") as json_file:\n        json.dump(get_dataframe_dtypes_metadata(df_uncleaned), json_file)\n    \n\n    # -------------------------------------------------------\n    # 4. Add new column if any missing w.r.t metadatajson\n    # -------------------------------------------------------\n    # Extract new columns data\n#     new_columns = check_if_any_new_column_formation_is_required(df_uncleaned, metadata_json)\n    \n#     # Create new columns\n#     for new_column in new_columns:\n#         new_column_name = new_column[0]\n#         new_column_df = execute_create_new_column_prompt(\n#             new_column,\n#             extract_df_column_names_with_datatypes(df_uncleaned)\n#         )\n#         # Concatenates column to the main dataset & remove duplicates column wise\n#         if new_column_name in new_column_df.columns:\n#             df_uncleaned = pd.concat([df_uncleaned, new_column_df], axis=1)\n#             df_uncleaned = df_uncleaned.loc[:,~df_uncleaned.columns.duplicated()]\n#             df_uncleaned = df_uncleaned.loc[:, ~df_uncleaned.columns.str.contains('^Unnamed')]\n    \n#     # -------------------------------------------------------\n#     # 5. Save modified dataset\n#     # -------------------------------------------------------\n#     df_uncleaned.to_csv('finalised.csv', index=False)\n#     with open('finalised_metadata.json', \"w\") as json_file:\n#         json.dump(get_dataframe_dtypes_metadata(df_uncleaned), json_file)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T05:13:39.732751Z","iopub.execute_input":"2024-03-28T05:13:39.733359Z","iopub.status.idle":"2024-03-28T05:13:39.744852Z","shell.execute_reply.started":"2024-03-28T05:13:39.733323Z","shell.execute_reply":"2024-03-28T05:13:39.743574Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"# Execution","metadata":{}},{"cell_type":"code","source":"%%time\n\n# try:\n#     execute_pipline()\n#     print(\"Execution successfull\")\n# except Exception as e:\n#     print(\"Execution failed: \", e)\n\nexecute_pipline()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T05:13:40.354319Z","iopub.execute_input":"2024-03-28T05:13:40.354709Z","iopub.status.idle":"2024-03-28T05:13:43.524167Z","shell.execute_reply.started":"2024-03-28T05:13:40.354677Z","shell.execute_reply":"2024-03-28T05:13:43.523329Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"['Name', 'Short Name', 'Description', 'Business Owner', 'Technical Owner', 'Number of Users', 'Recovery Point Objective', 'Recovery Time Objective', 'Go Live Date', 'End of Support Date', 'SLA Type', 'Vendor', 'Status', 'AGF Classification', 'DR Type', 'Required Availability', 'System Hosting Place', 'User Community', 'Type of System', 'Enterprise Level', 'Development Type', 'Recommendation', 'Cloud Migration Strategy', 'Architecture Type', 'Mobile Compliance', 'Multi Language Support']\nName                                object\nShort Name                          object\nDescription                         object\nBusiness Owner                    category\nTechnical Owner                   category\nNumber of Users                     object\nRecovery Point Objective            object\nRecovery Time Objective             object\nGo Live Date                datetime64[ns]\nEnd of Support Date         datetime64[ns]\nSLA Type                          category\nVendor                            category\nStatus                            category\nAGF Classification                category\nDR Type                           category\nRequired Availability             category\nSystem Hosting Place              category\nUser Community                    category\nType of System                    category\nEnterprise Level                  category\nDevelopment Type                  category\nRecommendation                    category\nCloud Migration Strategy          category\nArchitecture Type                 category\nMobile Compliance                 category\nMulti Language Support            category\ndtype: object\nCPU times: user 132 ms, sys: 3.18 ms, total: 135 ms\nWall time: 3.16 s\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('finalised.csv')\ndf.head(2)","metadata":{"execution":{"iopub.status.busy":"2024-03-27T16:28:01.127254Z","iopub.execute_input":"2024-03-27T16:28:01.128001Z","iopub.status.idle":"2024-03-27T16:28:01.259950Z","shell.execute_reply.started":"2024-03-27T16:28:01.127940Z","shell.execute_reply":"2024-03-27T16:28:01.258354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('finalised_metadata.json', 'r') as json_file:\n    data = json.load(json_file)\n    print(data)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T16:26:18.368469Z","iopub.execute_input":"2024-03-23T16:26:18.369479Z","iopub.status.idle":"2024-03-23T16:26:18.375205Z","shell.execute_reply.started":"2024-03-23T16:26:18.369441Z","shell.execute_reply":"2024-03-23T16:26:18.373949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ask_rta_bot('What is the User Community percentage w.r.t to its unique values')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ask_rta_bot('Check for data quality issues which should include missing values, unique values, duplicate values and their data types')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T16:49:13.006740Z","iopub.execute_input":"2024-03-23T16:49:13.007132Z","iopub.status.idle":"2024-03-23T16:49:19.476019Z","shell.execute_reply.started":"2024-03-23T16:49:13.007089Z","shell.execute_reply":"2024-03-23T16:49:19.474833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ask_rta_bot('Plot Pie chart of Status', df_uncleaned)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ask_rta_bot('Plot Bar graph of Status')","metadata":{"execution":{"iopub.status.busy":"2024-03-23T16:50:25.508593Z","iopub.execute_input":"2024-03-23T16:50:25.509373Z","iopub.status.idle":"2024-03-23T16:50:30.967173Z","shell.execute_reply.started":"2024-03-23T16:50:25.509339Z","shell.execute_reply":"2024-03-23T16:50:30.965949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json_data = {\n  \"# users\": \"Number of Users\",\n  \"RPO\": \"Recovery Point Objective\",\n  \"RTO\": \"Recovery Time Objective\",\n  \"start date\": \"Go Live Date\",\n  \"end date\": \"End of Support Date\",\n  \"SLA\": \"SLA Type\",\n  \"AGF score\": \"AGF Classification\",\n  \"DR TYpe\": \"DR Type\",\n  \"location\": \"\",\n  \"I/X\": \"User Community\",\n  \"Type of System (Gartner)\": \"Type of System\",\n  \"Across RTA?\": \"Enterprise Level\",\n  \"commercial or customized\": \"Development Type\",\n  \"Cloud Migration plan\": \"Cloud Migration Strategy\",\n  \"Type\": \"Architecture Type\",\n  \"Mobile compatible\": \"Mobile Compliance\",\n  \"support many langs\": \"Multi Language Support\"\n}\n\n# Remove keys with empty string or None values\njson_data = {key: value for key, value in json_data.items() if value != \"\" and value is not None}\njson_data\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T05:05:41.747070Z","iopub.execute_input":"2024-03-28T05:05:41.748080Z","iopub.status.idle":"2024-03-28T05:05:41.758117Z","shell.execute_reply.started":"2024-03-28T05:05:41.748040Z","shell.execute_reply":"2024-03-28T05:05:41.757071Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"{'# users': 'Number of Users',\n 'RPO': 'Recovery Point Objective',\n 'RTO': 'Recovery Time Objective',\n 'start date': 'Go Live Date',\n 'end date': 'End of Support Date',\n 'SLA': 'SLA Type',\n 'AGF score': 'AGF Classification',\n 'DR TYpe': 'DR Type',\n 'I/X': 'User Community',\n 'Type of System (Gartner)': 'Type of System',\n 'Across RTA?': 'Enterprise Level',\n 'commercial or customized': 'Development Type',\n 'Cloud Migration plan': 'Cloud Migration Strategy',\n 'Type': 'Architecture Type',\n 'Mobile compatible': 'Mobile Compliance',\n 'support many langs': 'Multi Language Support'}"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_excel(UNCLEANED_DATA_PATH)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T08:54:57.751241Z","iopub.execute_input":"2024-03-28T08:54:57.752876Z","iopub.status.idle":"2024-03-28T08:54:57.919410Z","shell.execute_reply.started":"2024-03-28T08:54:57.752826Z","shell.execute_reply":"2024-03-28T08:54:57.917735Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Column data types\ndata_types = df.dtypes\n\n# Missing values percentage\nmissing_percentage = (df.isnull().sum() / len(df)) * 100\n\n# Non-missing values count\nnon_missing_count = df.notnull().sum()\n\n# Duplicate values\nduplicate_count = df.duplicated().sum()\n\n# Unique values count\nunique_values_count = df.nunique()\n\n# Most frequent value and its frequency\ntop_frequency = df.mode().iloc[0]\n\n# Create summary DataFrame\nsummary_data = {\n    'Data Types': data_types,\n    'Non-missing Values Count': non_missing_count,\n    'Missing Values (%)': missing_percentage,\n    'Duplicate Values Count': duplicate_count,\n    'Unqiue Values Count': unique_values_count,\n    'Top Frequent Value': top_frequency,\n}\n\nsummary_df = pd.DataFrame(summary_data)\nsummary_df = summary_df.rename_axis('Attribute Names')\nsummary_df","metadata":{"execution":{"iopub.status.busy":"2024-03-28T08:57:34.238891Z","iopub.execute_input":"2024-03-28T08:57:34.239287Z","iopub.status.idle":"2024-03-28T08:57:34.287151Z","shell.execute_reply.started":"2024-03-28T08:57:34.239259Z","shell.execute_reply":"2024-03-28T08:57:34.286029Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"                              Data Types  Non-missing Values Count  \\\nAttribute Names                                                      \nName                              object                       100   \nShort Name                        object                       100   \nDescription                       object                       100   \nBusiness Owner                    object                       100   \nTechnical Owner                   object                       100   \n# users                           object                        56   \nRPO                               object                        26   \nRTO                               object                        27   \nstart date                datetime64[ns]                        57   \nend date                  datetime64[ns]                        58   \nSLA                               object                        33   \nVendor                            object                       100   \nStatus                            object                        88   \nAGF score                         object                        93   \nDR TYpe                           object                        28   \nRequired Availability             object                        45   \nlocation                          object                        62   \nI/X                               object                        84   \nType of System (Gartner)          object                        68   \nAcross RTA?                       object                        84   \ncommercial or customized          object                       100   \nRecommendation                    object                       100   \nCloud Migration plan              object                       100   \nType                              object                       100   \nMobile compatible                 object                        78   \nsupport many langs                object                       100   \n\n                          Missing Values (%)  Duplicate Values Count  \\\nAttribute Names                                                        \nName                                     0.0                       0   \nShort Name                               0.0                       0   \nDescription                              0.0                       0   \nBusiness Owner                           0.0                       0   \nTechnical Owner                          0.0                       0   \n# users                                 44.0                       0   \nRPO                                     74.0                       0   \nRTO                                     73.0                       0   \nstart date                              43.0                       0   \nend date                                42.0                       0   \nSLA                                     67.0                       0   \nVendor                                   0.0                       0   \nStatus                                  12.0                       0   \nAGF score                                7.0                       0   \nDR TYpe                                 72.0                       0   \nRequired Availability                   55.0                       0   \nlocation                                38.0                       0   \nI/X                                     16.0                       0   \nType of System (Gartner)                32.0                       0   \nAcross RTA?                             16.0                       0   \ncommercial or customized                 0.0                       0   \nRecommendation                           0.0                       0   \nCloud Migration plan                     0.0                       0   \nType                                     0.0                       0   \nMobile compatible                       22.0                       0   \nsupport many langs                       0.0                       0   \n\n                          Unqiue Values Count  \\\nAttribute Names                                 \nName                                       98   \nShort Name                                 97   \nDescription                               100   \nBusiness Owner                             20   \nTechnical Owner                            19   \n# users                                    48   \nRPO                                        14   \nRTO                                        13   \nstart date                                 39   \nend date                                   43   \nSLA                                         4   \nVendor                                     30   \nStatus                                      3   \nAGF score                                   4   \nDR TYpe                                     5   \nRequired Availability                       3   \nlocation                                    3   \nI/X                                         3   \nType of System (Gartner)                    3   \nAcross RTA?                                 2   \ncommercial or customized                    2   \nRecommendation                              4   \nCloud Migration plan                        6   \nType                                        7   \nMobile compatible                           3   \nsupport many langs                          2   \n\n                                                         Top Frequent Value  \nAttribute Names                                                              \nName                                                                  Asana  \nShort Name                                                           Accela  \nDescription                A centralized system used to manage customer ...  \nBusiness Owner                                                  Procurement  \nTechnical Owner                 Sustainability and Environmental Compliance  \n# users                                                                  20  \nRPO                                                              15 minutes  \nRTO                                                                   4 hrs  \nstart date                                              2015-01-01 00:00:00  \nend date                                                2024-12-31 00:00:00  \nSLA                                                                    Gold  \nVendor                                                Dynamic Data Services  \nStatus                                                                 Live  \nAGF score                                                                 4  \nDR TYpe                                                      Active-Passive  \nRequired Availability                                         99.0% - 99.5%  \nlocation                                                         On Premise  \nI/X                                                                       I  \nType of System (Gartner)                                   System of Record  \nAcross RTA?                                                              No  \ncommercial or customized                                         customized  \nRecommendation                                                       Retire  \nCloud Migration plan                                                 Retain  \nType                                                            Stand-Alone  \nMobile compatible                                           Fully Supported  \nsupport many langs                                                      Yes  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data Types</th>\n      <th>Non-missing Values Count</th>\n      <th>Missing Values (%)</th>\n      <th>Duplicate Values Count</th>\n      <th>Unqiue Values Count</th>\n      <th>Top Frequent Value</th>\n    </tr>\n    <tr>\n      <th>Attribute Names</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Name</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>98</td>\n      <td>Asana</td>\n    </tr>\n    <tr>\n      <th>Short Name</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>97</td>\n      <td>Accela</td>\n    </tr>\n    <tr>\n      <th>Description</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>100</td>\n      <td>A centralized system used to manage customer ...</td>\n    </tr>\n    <tr>\n      <th>Business Owner</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>20</td>\n      <td>Procurement</td>\n    </tr>\n    <tr>\n      <th>Technical Owner</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>19</td>\n      <td>Sustainability and Environmental Compliance</td>\n    </tr>\n    <tr>\n      <th># users</th>\n      <td>object</td>\n      <td>56</td>\n      <td>44.0</td>\n      <td>0</td>\n      <td>48</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>RPO</th>\n      <td>object</td>\n      <td>26</td>\n      <td>74.0</td>\n      <td>0</td>\n      <td>14</td>\n      <td>15 minutes</td>\n    </tr>\n    <tr>\n      <th>RTO</th>\n      <td>object</td>\n      <td>27</td>\n      <td>73.0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>4 hrs</td>\n    </tr>\n    <tr>\n      <th>start date</th>\n      <td>datetime64[ns]</td>\n      <td>57</td>\n      <td>43.0</td>\n      <td>0</td>\n      <td>39</td>\n      <td>2015-01-01 00:00:00</td>\n    </tr>\n    <tr>\n      <th>end date</th>\n      <td>datetime64[ns]</td>\n      <td>58</td>\n      <td>42.0</td>\n      <td>0</td>\n      <td>43</td>\n      <td>2024-12-31 00:00:00</td>\n    </tr>\n    <tr>\n      <th>SLA</th>\n      <td>object</td>\n      <td>33</td>\n      <td>67.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>Gold</td>\n    </tr>\n    <tr>\n      <th>Vendor</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>30</td>\n      <td>Dynamic Data Services</td>\n    </tr>\n    <tr>\n      <th>Status</th>\n      <td>object</td>\n      <td>88</td>\n      <td>12.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Live</td>\n    </tr>\n    <tr>\n      <th>AGF score</th>\n      <td>object</td>\n      <td>93</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>DR TYpe</th>\n      <td>object</td>\n      <td>28</td>\n      <td>72.0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>Active-Passive</td>\n    </tr>\n    <tr>\n      <th>Required Availability</th>\n      <td>object</td>\n      <td>45</td>\n      <td>55.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>99.0% - 99.5%</td>\n    </tr>\n    <tr>\n      <th>location</th>\n      <td>object</td>\n      <td>62</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>On Premise</td>\n    </tr>\n    <tr>\n      <th>I/X</th>\n      <td>object</td>\n      <td>84</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>I</td>\n    </tr>\n    <tr>\n      <th>Type of System (Gartner)</th>\n      <td>object</td>\n      <td>68</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>System of Record</td>\n    </tr>\n    <tr>\n      <th>Across RTA?</th>\n      <td>object</td>\n      <td>84</td>\n      <td>16.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>No</td>\n    </tr>\n    <tr>\n      <th>commercial or customized</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>customized</td>\n    </tr>\n    <tr>\n      <th>Recommendation</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>Retire</td>\n    </tr>\n    <tr>\n      <th>Cloud Migration plan</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>Retain</td>\n    </tr>\n    <tr>\n      <th>Type</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>Stand-Alone</td>\n    </tr>\n    <tr>\n      <th>Mobile compatible</th>\n      <td>object</td>\n      <td>78</td>\n      <td>22.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Fully Supported</td>\n    </tr>\n    <tr>\n      <th>support many langs</th>\n      <td>object</td>\n      <td>100</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Yes</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}